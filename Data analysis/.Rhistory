barplot(mean_20)
par(mfrow=c(1,1))
barplot(mean_19)
barplot(mean_20)
par(mfrow=c(2,1))
barplot(mean_19)
barplot(mean_20)
par(mfrow=c(1,2))
barplot(mean_19)
barplot(mean_20)
barplot(mean_19, names=c("1월", "2월", "3월", "4월", "5월", "6월", "7월", "8월", "9월", "10월", "10월", "11월"))
barplot(mean_19, names=c("1월", "2월", "3월", "4월", "5월", "6월", "7월", "8월", "9월", "10월", "11월"))
par(mfrow=c(1,2))
barplot(mean_19, names=c("1월", "2월", "3월", "4월", "5월", "6월", "7월", "8월", "9월", "10월", "11월"))
library(RColorBrewer)
barplot(mean_19, names=c("1월", "2월", "3월", "4월", "5월", "6월", "7월", "8월", "9월", "10월", "11월"),
main="2019년 서울시 미세먼지 월 별 평균", col=brewer.pal(11, "Set2"))
par(mfrow=c(1,2))
barplot(mean_19, names=c("1월", "2월", "3월", "4월", "5월", "6월", "7월", "8월", "9월", "10월", "11월"),
main="2019년 서울시 미세먼지 월 별 평균", col=brewer.pal(11, "Set2"))
barplot(mean_20, names=c("1월", "2월", "3월", "4월", "5월", "6월", "7월", "8월", "9월", "10월", "11월"),
main="2020년 서울시 미세먼지 월 별 평균", col=brewer.pal(11, "Set2"))
barplot(mean_19, names=c("1월", "2월", "3월", "4월", "5월", "6월", "7월", "8월", "9월", "10월", "11월"),
main="2019년 서울시 미세먼지 월 별 평균", col=brewer.pal(11, "Set2"), ylim=c(0,80))
barplot(mean_19, names=c("1월", "2월", "3월", "4월", "5월", "6월", "7월", "8월", "9월", "10월", "11월"),
main="2019년 서울시 미세먼지 월 별 평균", col=brewer.pal(11, "Set2"), ylim=c(0, 80))
barplot(mean_20, names=c("1월", "2월", "3월", "4월", "5월", "6월", "7월", "8월", "9월", "10월", "11월"),
main="2020년 서울시 미세먼지 월 별 평균", col=brewer.pal(11, "Set2"), ylim=c(0, 80))
par(mfrow=c(1,2))
barplot(mean_19, names=c("1월", "2월", "3월", "4월", "5월", "6월", "7월", "8월", "9월", "10월", "11월"),
main="2019년 서울시 미세먼지 월 별 평균", col=brewer.pal(11, "Set2"), ylim=c(0, 80))
barplot(mean_20, names=c("1월", "2월", "3월", "4월", "5월", "6월", "7월", "8월", "9월", "10월", "11월"),
main="2020년 서울시 미세먼지 월 별 평균", col=brewer.pal(11, "Set2"), ylim=c(0, 80))
load("~/.RData")
library(rvest)
base_url <- "https://movie.naver.com/movie/point/af/list.nhn?st=mcode&sword=157297&target=&page="
reviews <- c()
for(i in 1:1){
url <- paste(base_url, i, sep = "")
html <- read_html(url, encoding = 'CP949')
table <- html_nodes(html, '.list_netizen')
text <- html_nodes(table, '.title')
review <- html_text(text)
reviews <- c(reviews, review)
}
reviews
for(i in 1:2){
url <- paste(base_url, i, sep = "")
html <- read_html(url, encoding = 'CP949')
table <- html_nodes(html, '.list_netizen')
text <- html_nodes(table, '.title')
review <- html_text(text)
reviews <- c(reviews, review)
}
eliminate <- function(data){
data %>%
gsub("\r", "", .) %>%
gsub("\t", "", .) %>%
gsub("\n", "", .)
}
base_url <- "https://movie.naver.com/movie/point/af/list.nhn?st=mcode&sword=157297&target=&page="
reviews <- c()
for(i in 1:2){
url <- paste(base_url, i, sep = "")
html <- read_html(url, encoding = 'CP949')
table <- html_nodes(html, '.list_netizen')
text <- html_nodes(table, '.title')
review <- html_text(text)
reviews <- c(reviews, review) %>%
eliminate()
}
reviews
for(i in 1:2){
url <- paste(base_url, i, sep = "")
html <- read_html(url, encoding = 'CP949')
table <- html_nodes(html, '.list_netizen')
text <- html_nodes(table, '.title')
review <- html_text(text) %>%
eliminate() %>%
strsplit(., "중")[[1]][2]
reviews <- c(reviews, review)
}
for(i in 1:2){
url <- paste(base_url, i, sep = "")
html <- read_html(url, encoding = 'CP949')
table <- html_nodes(html, '.list_netizen')
text <- html_nodes(table, '.title')
review <- html_text(text) %>%
eliminate()
reviews <- c(reviews, review)
}
review
for(i in 1:2){
url <- paste(base_url, i, sep = "")
html <- read_html(url, encoding = 'CP949')
table <- html_nodes(html, '.list_netizen')
text <- html_nodes(table, '.title')
review <- html_text(text) %>%
eliminate()
for(i in 1:10){
review[i] %<>%
strsplit(., "중")[[1]][2]
}
reviews <- c(reviews, review)
}
library(magrittr)
for(i in 1:2){
url <- paste(base_url, i, sep = "")
html <- read_html(url, encoding = 'CP949')
table <- html_nodes(html, '.list_netizen')
text <- html_nodes(table, '.title')
review <- html_text(text) %>%
eliminate()
for(i in 1:10){
review[i] %<>%
strsplit(., "중")[[1]][2]
}
reviews <- c(reviews, review)
}
strsplit(review[1], "중")
strsplit(review[1], "중")[2]
strsplit(review[1], "중")[[1]][2]
reviews <- c()
for(i in 1:2){
url <- paste(base_url, i, sep = "")
html <- read_html(url, encoding = 'CP949')
table <- html_nodes(html, '.list_netizen')
text <- html_nodes(table, '.title')
review <- html_text(text) %>%
eliminate()
for(i in 1:10){
review[i] <- strsplit( review[i], "중")[[1]][2]
}
reviews <- c(reviews, review)
}
reviews
review[1][1]
review[1][1:2]
reviews <- c()
for(i in 1:2){
url <- paste(base_url, i, sep = "")
html <- read_html(url, encoding = 'CP949')
table <- html_nodes(html, '.list_netizen')
text <- html_nodes(table, '.title')
review <- html_text(text) %>%
eliminate()
for(i in 1:10){
review[i] <- strsplit( review[i], "중")[[1]][2] %>%
gsub("[0-9]", "")
}
reviews <- c(reviews, review)
}
reviews
library(plyr)
library(stringr)
reviews <- c()
for(i in 1:2){
url <- paste(base_url, i, sep = "")
html <- read_html(url, encoding = 'CP949')
table <- html_nodes(html, '.list_netizen')
text <- html_nodes(table, '.title')
review <- html_text(text) %>%
eliminate()
for(i in 1:10){
review[i] <- strsplit( review[i], "중")[[1]][2] %>%
gsub('\\d+', '', sentence)
}
reviews <- c(reviews, review)
}
for(i in 1:2){
url <- paste(base_url, i, sep = "")
html <- read_html(url, encoding = 'CP949')
table <- html_nodes(html, '.list_netizen')
text <- html_nodes(table, '.title')
review <- html_text(text) %>%
eliminate()
for(i in 1:10){
review[i] <- strsplit( review[i], "중")[[1]][2] %>%
gsub('\\d+', '', .)
}
reviews <- c(reviews, review)
}
reviews
setwd("~/Desktop/R/Text Mining")
positive <- readLines("./data/positive.txt", encoding="UTF-8")
positive
positive <- positive[-1]
positive
negative <- readLines("./data/negative.txt", encoding="UTF-8")
negative <- negative[-1]
sentimental <- function(sentences, positive, negative){
scores = laply(sentences, function(sentence, positive, negative) {
word.list = str_split(sentence, '\\s+')      # 공백 기준으로 단어 생성 -> \\s+ : 공백 정규식, +(1개 이상)
words = unlist(word.list)                    # unlist() : list를 vector 객체로 구조변경
pos.matches = match(words, positive)           # words의 단어를 positive에서 matching
neg.matches = match(words, negative)
pos.matches = !is.na(pos.matches)            # NA 제거, 위치(숫자)만 추출
neg.matches = !is.na(neg.matches)
score = sum(pos.matches) - sum(neg.matches)  # 긍정 - 부정
return(score)
}, positive, negative)
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
sentimental(reviews, positive, negative)
result=sentimental(reviews, positive, negative)
result$color[result$score >=1] = "blue"
result$color[result$score ==0] = "green"
result$color[result$score < 0] = "red"
result
result %<>% table()
result
sentiment_result= table(result$remark)
result=sentimental(reviews, positive, negative)
result$color[result$score >=1] = "blue"
result$color[result$score ==0] = "green"
result$color[result$score < 0] = "red"
sentiment_result= table(result$remark)
sentiment_result
result$remark[result$score >=1] = "긍정"
result$remark[result$score ==0] = "중립"
result$remark[result$score < 0] = "부정"
sentiment_result= table(result$remark)
sentiment_result
barplot(sentiment_result)
barplot(sentiment_result, col = c("blue", "green", "red"))
base_url <- "https://movie.naver.com/movie/point/af/list.nhn?st=mcode&sword=66834&target=&page="
reviews <- c()
for(i in 1:2){
base_url <- "https://movie.naver.com/movie/point/af/list.nhn?st=mcode&sword=66834&target=&page="
reviews <- c()
base_url <- "https://movie.naver.com/movie/point/af/list.nhn?st=mcode&sword=66834&target=&page="
reviews <- c()
for(i in 1:2){
for(i in 1:2){
url <- paste(base_url, i, sep = "")
html <- read_html(url, encoding = 'CP949')
table <- html_nodes(html, '.list_netizen')
text <- html_nodes(table, '.title')
review <- html_text(text) %>%
eliminate()
for(i in 1:10){
review[i] <- strsplit( review[i], "중")[[1]][2] %>%
gsub('\\d+', '', .) %>%
gsub('[[:punct:]]', '', sentence) %>%
gsub('[[:cntrl:]]', '', sentence
}
reviews <-
for(i in 1:2){
url <- paste(base_url, i, sep = "")
html <- read_html(url, encoding = 'CP949')
table <- html_nodes(html, '.list_netizen')
text <- html_nodes(table, '.title')
review <- html_text(text) %>%
eliminate()
for(i in 1:10){
review[i] <- strsplit( review[i], "중")[[1]][2] %>%
gsub('\\d+', '', .) %>%
gsub('[[:punct:]]', '', sentence) %>%
gsub('[[:cntrl:]]', '', sentence
}
reviews <- c(reviews, review)
}
for(i in 1:2){
url <- paste(base_url, i, sep = "")
html <- read_html(url, encoding = 'CP949')
table <- html_nodes(html, '.list_netizen')
text <- html_nodes(table, '.title')
review <- html_text(text) %>%
eliminate()
for(i in 1:10){
review[i] <- strsplit( review[i], "중")[[1]][2] %>%
gsub('\\d+', '', .) %>%
gsub('[[:punct:]]', '', sentence) %>%
gsub('[[:cntrl:]]', '', sentence
}
reviews <- c(reviews, review)
}
for(i in 1:2){
url <- paste(base_url, i, sep = "")
html <- read_html(url, encoding = 'CP949')
table <- html_nodes(html, '.list_netizen')
text <- html_nodes(table, '.title')
review <- html_text(text) %>%
eliminate()
for(i in 1:10){
review[i] <- strsplit( review[i], "중")[[1]][2] %>%
gsub('\\d+', '', .) %>%
gsub('[[:punct:]]', '', sentence) %>%
gsub('[[:cntrl:]]', '', sentence
}
reviews <- c(reviews, review)
}
for(i in 1:2){
library(rvest)
library(magrittr)
library(plyr)
library(stringr)
library(rvest)
library(magrittr)
library(plyr)
library(stringr)
eliminate <- function(data){
data %>%
gsub("\r", "", .) %>%
gsub("\t", "", .) %>%
gsub("\n", "", .)
}
base_url <- "https://movie.naver.com/movie/point/af/list.nhn?st=mcode&sword=66834&target=&page="
reviews <- c()
for(i in 1:2){
url <- paste(base_url, i, sep = "")
html <- read_html(url, encoding = 'CP949')
table <- html_nodes(html, '.list_netizen')
text <- html_nodes(table, '.title')
review <- html_text(text) %>%
eliminate()
for(j in 1:10){
review[j] <- strsplit( review[j], "중")[[1]][2] %>%
gsub('\\d+', '', .) %>%
gsub('[[:punct:]]', '', sentence) %>%
gsub('[[:cntrl:]]', '', sentence
}
}
reviews <- c()
for(i in 1:2){
url <- paste(base_url, i, sep = "")
html <- read_html(url, encoding = 'CP949')
table <- html_nodes(html, '.list_netizen')
text <- html_nodes(table, '.title')
review <- html_text(text) %>%
eliminate()
for(j in 1:10){
review[j] <- strsplit( review[j], "중")[[1]][2] %>%
gsub('\\d+', '', .) %>%
gsub('[[:punct:]]', '', sentence) %>%
gsub('[[:cntrl:]]', '', sentence)
}
reviews <- c(reviews, review)
}
reviews <- c()
for(i in 1:2){
url <- paste(base_url, i, sep = "")
html <- read_html(url, encoding = 'CP949')
table <- html_nodes(html, '.list_netizen')
text <- html_nodes(table, '.title')
review <- html_text(text) %>%
eliminate()
for(j in 1:10){
review[j] <- strsplit( review[j], "중")[[1]][2] %>%
gsub('\\d+', '', .) %>%
gsub('[[:punct:]]', '', .) %>%
gsub('[[:cntrl:]]', '', .)
}
reviews <- c(reviews, review)
}
positive <- readLines("./data/positive.txt", encoding="UTF-8")
positive <- positive[-1]
negative <- readLines("./data/negative.txt", encoding="UTF-8")
negative <- negative[-1]
sentimental <- function(sentences, positive, negative){
scores = laply(sentences, function(sentence, positive, negative) {
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)
pos.matches = match(words, positive)
neg.matches = match(words, negative)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, positive, negative)
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
result=sentimental(reviews, positive, negative)
result$color[result$score >=1] = "blue"
result$color[result$score ==0] = "green"
result$color[result$score < 0] = "red"
result$remark[result$score >=1] = "긍정"
result$remark[result$score ==0] = "중립"
result$remark[result$score < 0] = "부정"
sentiment_result= table(result$remark)
sentiment_result
barplot(sentiment_result, col = c("blue", "green", "red"))
reviews
for(i in 1:100){
url <- paste(base_url, i, sep = "")
html <- read_html(url, encoding = 'CP949')
table <- html_nodes(html, '.list_netizen')
text <- html_nodes(table, '.title')
review <- html_text(text) %>%
eliminate()
for(j in 1:10){
review[j] <- strsplit( review[j], "중")[[1]][2] %>%
gsub('\\d+', '', .) %>%
gsub('[[:punct:]]', '', .) %>%
gsub('[[:cntrl:]]', '', .)
}
reviews <- c(reviews, review)
}
reviews<- reviews[-which(nchar(reviews) == 0)]
reviews
reviews <- reviews[order(nchar(reviews), decreasing = TRUE)]
reviews <- reviews[1:20]
reviews
positive <- readLines("./data/positive.txt", encoding="UTF-8")
positive <- positive[-1]
negative <- readLines("./data/negative.txt", encoding="UTF-8")
negative <- negative[-1]
sentimental <- function(sentences, positive, negative){
scores = laply(sentences, function(sentence, positive, negative) {
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)
pos.matches = match(words, positive)
neg.matches = match(words, negative)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, positive, negative)
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
result=sentimental(reviews, positive, negative)
result$color[result$score >=1] = "blue"
result$color[result$score ==0] = "green"
result$color[result$score < 0] = "red"
result$remark[result$score >=1] = "긍정"
result$remark[result$score ==0] = "중립"
result$remark[result$score < 0] = "부정"
sentiment_result = table(result$remark)
sentiment_result
barplot(sentiment_result, col = c("blue", "green", "red"))
setwd("~/Desktop/R/Data analysis")
data <- read.csv("./data/car_data.csv")
data <- read.csv("./data/car_data.csv", fileEncoding = "CP949")
data
가솔린 <- NA
디젤 <- NA
temp <- cbind(data,가솔린, 디젤)
head(temp)
library("car")
library("psych")
pairs.panels(temp[names(temp)])
data <- read.csv("./data/car_data.csv", fileEncoding = "CP949")
#NA 제거
dim(data)
data <- data[complete.cases(data), ]
가솔린 <- NA
디젤 <- NA
temp <- cbind(data,가솔린, 디젤)
head(temp)
temp$가솔린[temp$연료 == "가솔린"] <- 1
temp$가솔린[is.na(temp$가솔린)] <- 0
temp$디젤[temp$연료 == "디젤"] <- 1
temp$디젤[is.na(temp$디젤)] <- 0
#0과 1을 factor로 처리
temp$가솔린 <- as.factor(temp$가솔린)
temp$디젤 <- as.factor(temp$디젤)
colnames(temp)
temp <- temp[,-8]
#나머지 범주형 데이터를 factor처리
temp$년식 <- as.factor(temp$년식)
temp$LPG <- as.factor(temp$LPG)
temp$회사명 <- as.factor(temp$회사명)
temp$종류 <- as.factor(temp$종류)
temp$하이브리드 <- as.factor(temp$하이브리드)
temp$변속기 <- as.factor(temp$변속기)
#전체데이터로 회귀모형 생성
fit <- lm(가격~., data = temp)
summary(fit)
fit.con <- lm(가격~1,data = temp)
fit.forward <- step(fit.con,scope=list(lower=fit.con,upper=fit),direction = "forward")
summary(fit.forward)
fit.backward <- step(fit, scope = list(lower = fit.con, upper = fit),
direction = "backward")
summary(fit.backward) #결정계수 : 0.8439
fit.both <- step(fit.con, scope = list(lower = fit.con, upper = fit), direction = "both")
summary(fit.both)
fit <- lm(가격 ~ 마력 + 회사명 + 종류 + 배기량 + 하이브리드 +
중량 + 변속기 + 년식 + 연비 + 디젤 + 토크, data = temp)
library("car")
library("psych")
pairs.panels(temp[names(temp)])
vif(fit)
fit1 <- lm(가격 ~ 마력 + 회사명 + 종류 + 배기량 + 하이브리드 + 중량 + 변속기 + 년식 + 연비 + 디젤, data = temp)
vif(fit1)
fit2 <- lm(가격 ~ 마력 + 회사명 + 종류 + 배기량 + 하이브리드 + 변속기 + 년식 + 연비 + 디젤, data = temp)
vif(fit2)
fit3 <- lm(가격 ~ 마력 + 회사명 + 종류  + 하이브리드 + 변속기 + 년식 + 연비 + 디젤, data = temp)
vif(fit3)
summary(fit3)
par(mfrow=c(2,2))
plot(fit3)
fit <- lm(가격 ~ 마력 + 회사명 + 종류  + 하이브리드 + 변속기 + 년식 + 연비 + 디젤, data = temp[-c(3,4,10),])
summary(fit)
par(mfrow=c(2,2))
plot(fit)
pre <- predict(fit, newdata = temp)
pre <- as.data.frame(pre)
head(pre)
pre <- predict(fit, newdata = temp, interval = "predict")
pre <- as.data.frame(pre)
head(pre)
pre <- cbind(pre, temp$가격)
head(pre)
tf <- NA
pre <- cbind(pre, tf)
pre$tf[pre$`temp$가격`>= pre$lwr & pre$`temp$가격` <= pre$upr] <- T
pre$tf[is.na(pre$tf)] <- F
head(pre)
sum(pre$tf=="TRUE")/dim(pre)[1]
